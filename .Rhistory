require(devtools)
install_github('rCharts', 'ramnathv')
names(iris) = gsub("\\.", "", names(iris))
rPlot(SepalLength ~ SepalWidth | Species, data = iris, color = 'Species', type = 'point')
library(rCharts)
names(iris) = gsub("\\.", "", names(iris))
rPlot(SepalLength ~ SepalWidth | Species, data = iris, color = 'Species', type = 'point')
names(iris) = gsub("\\.", "", names(iris))
rPlot(SepalLength ~ SepalWidth | Species, data = iris, color = 'Species', type = 'point')
rPlot()
names(iris) = gsub("\\.", "", names(iris))
library(rCharts)
rPlot(SepalLength ~ SepalWidth | Species, data = iris, color = 'Species', type = 'point')
## Example 2 Facetted Barplot
hair_eye = as.data.frame(HairEyeColor)
rPlot(Freq ~ Hair | Eye, color = 'Eye', data = hair_eye, type = 'bar')
names(iris) = gsub("\\.", "", names(iris))
r1 <- rPlot(SepalLength ~ SepalWidth | Species, data = iris,
color = 'Species', type = 'point')
r1$publish('Scatterplot', host = 'gist')
library(knitr)
hair_eye_male = subset(as.data.frame(HairEyeColor), Sex == "Male")
n1 <- nPlot(Freq ~ Hair, group = 'Eye',
data = hair_eye_male, type = 'multiBarChart'
)
n1$set(width = 600)
opts_chunk$set(comment = NA, results = "asis", comment = NA, tidy = F)
n1$show('inline', include_assets = TRUE, cdn = TRUE)
knit2html(n1$show('inline', include_assets = TRUE, cdn = TRUE))
source('~/.active-rstudio-document', echo=TRUE)
train[,-c("classe")]
train[,-"classe"]
train[,-9]
train[,c("classe")]
train[,-c("classe")]
train[,c("classe")]
findCorrelation(cor(train_wo_na[ , -which(names(train_wo_nace) %in% c("classe"))]))
findCorrelation(cor(train_wo_na[ , -which(names(train_wo_na) %in% c("classe"))]))
cor(train_wo_na[ , -which(names(train_wo_na) %in% c("classe"))])
findCorrelation(cor(train_wo_na[ , -which(names(train_wo_na) %in% c("classe"))]))
?findCorrelation
findCorrelation(cor(train_wo_na[ , -which(names(train_wo_na) %in% c("classe"))]), cutoff = 0.99)
findCorrelation(cor(train_wo_na[ , -which(names(train_wo_na) %in% c("classe"))]), cutoff = 0.75)
findCorrelation(cor(train_wo_na[ , -which(names(train_wo_na) %in% c("classe"))]), cutoff = 0.95)
View(train_wo_na)
View(cor(train_wo_na[ , -which(names(train_wo_na) %in% c("classe"))]))
toRemove <- findCorrelation(cor(train_wo_na[ , -which(names(train_wo_na) %in% c("classe"))]), cutoff = 0.95)
train <- train_wo_na[,-toRemove]
View(train)
toRemove <- findCorrelation(cor(train_wo_na[ , -which(names(train_wo_na) %in% c("classe"))]))
train <- train_wo_na[,-toRemove]
comboInfo <- findLinearCombos(train[ , -which(names(train) %in% c("classe"))])
comboInfo
?createDataPartition
trainIndex <- createDataPartition(train$classe, p = .6, list = FALSE)
train_train <- train[trainIndex,]
train_test <- train[-trainIndex,]
?trainControl
fitControl <- trainControl(method = "boot", number = 25)
fitControl <- trainControl(method = "boot", number = 25)
set.seed(825)
rf <- train(classe ~ ., data = train_train, method = "rf", trControl = fitControl, verbose = FALSE)
rf
source('~/.active-rstudio-document', echo=TRUE)
rf
source('~/.active-rstudio-document', echo=TRUE)
train <- read.csv(curl::curl("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"), na.strings = c("#DIV/0!", "NA"), stringsAsFactors = F)
test <- read.csv(curl::curl("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"), na.strings = c("#DIV/0!", "NA"), stringsAsFactors = F)
# train$classe <- as.factor(train$classe)
# test$classe <- as.factor(test$classe)
# get a sample from training data to work with
train <- train %>% sample_frac(1)
# from manually looking at the dataset, there seem to be a lot of "#DIV/0!" values (probably stemming from excel)
# replace those with NA
# remove columns which have more than 25% NAs
train_wo_na <- train[, colSums(!is.na(train)) > nrow(train) * 0.75]
# the first 7 variables don't seem to have any predictive value
train_wo_na <- train_wo_na %>% select(-(1:7))
# remove near zero values according to http://topepo.github.io/caret/preprocess.html#nzv
nzv <- nearZeroVar(train_wo_na, saveMetrics= TRUE)
nzv
nzv[nzv$nzv,]
# seems that there are no nzvs
# correlations
toRemove <- findCorrelation(cor(train_wo_na[ , -which(names(train_wo_na) %in% c("classe"))]))
# according to caret we should remove columns with indices 10, 1, 8 because they have a high pairwise correlation
train <- train_wo_na[,-toRemove]
# linear combos
comboInfo <- findLinearCombos(train[ , -which(names(train) %in% c("classe"))])
# there are obviously no linear combinations
# split into train and test sets
set.seed(3456)
trainIndex <- createDataPartition(train$classe, p = .6, list = FALSE)
train_train <- train[trainIndex,]
train_test <- train[-trainIndex,]
train_train$classe <- factor(train_train$classe)
train_test$classe <- factor(train_test$classe)
fitControl <- trainControl(method = "boot", number = 10)
set.seed(825)
rf <- train(classe ~ ., data = train_train, method = "rf", trControl = fitControl, verbose = FALSE)
rf
plot(rf)
trellis.par.set(caretTheme())
plot(rf)
predictions <- predict(rf, train_test)
confusionMatrix(predictions, train_train$classe)
train_train$classe
predictions
confusionMatrix(predictions, train_test$classe)
rf
?rf
rf
confusionMatrix(predictions, train_test$classe)
# reduced the repeats of bootstrap because it takes too long
fitControl <- trainControl(method = "boot", number = 10)
# custom tuning grid
rfGrid <- expand.grid(mtry = c(5, 10, 20, 25, 30))
set.seed(825)
rf <- train(classe ~ ., data = train_train,
method = "rf",
trControl = fitControl,
verbose = FALSE,
tuneGrid = rfGrid)
rf
## the RF model gives a very good accuracy of 0.988 on the training set
# lets try it on the validation set
trellis.par.set(caretTheme())
plot(rf)
predictions <- predict(rf, train_validation)
confusionMatrix(predictions, train_validation$classe)
# on the train and validation set, the model performs exceptionally well - interestingly, it performs even better on the validation set than the set it was trained on
train <- read.csv(curl::curl("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"), na.strings = c("#DIV/0!", "NA"), stringsAsFactors = F)
test <- read.csv(curl::curl("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"), na.strings = c("#DIV/0!", "NA"), stringsAsFactors = F)
# train$classe <- as.factor(train$classe)
# test$classe <- as.factor(test$classe)
# get a sample from training data to work with
# train <- train %>% sample_frac(1)
# from manually looking at the dataset, there seem to be a lot of "#DIV/0!" values (probably stemming from excel)
# replace those with NA
# remove columns which have more than 25% NAs
train_wo_na <- train[, colSums(!is.na(train)) > nrow(train) * 0.75]
# the first 7 variables don't seem to have any predictive value
train_wo_na <- train_wo_na %>% select(-(1:7))
# remove near zero values according to http://topepo.github.io/caret/preprocess.html#nzv
nzv <- nearZeroVar(train_wo_na, saveMetrics= TRUE)
nzv
nzv[nzv$nzv,]
# seems that there are no nzvs
# correlations
toRemove <- findCorrelation(cor(train_wo_na[ , -which(names(train_wo_na) %in% c("classe"))]))
# according to caret we should remove columns with indices 10, 1, 8 because they have a high pairwise correlation
train <- train_wo_na[,-toRemove]
# linear combos
comboInfo <- findLinearCombos(train[ , -which(names(train) %in% c("classe"))])
# there are obviously no linear combinations
# split into train and validation sets
set.seed(3456)
trainIndex <- createDataPartition(train$classe, p = .6, list = FALSE)
train_train <- train[trainIndex,]
train_validation <- train[-trainIndex,]
train_train$classe <- factor(train_train$classe)
train_validation$classe <- factor(train_validation$classe)
predictions <- predict(rf, train_validation)
confusionMatrix(predictions, train_validation$classe)
test$classe <- factor(test$classe)
# now the model is evaluated on the final test set with 20 test cases
predictions <- predict(rf, test)
confusionMatrix(predictions, test$classe)
# pml_write_files = function(x){
#   n = length(x)
#   for(i in 1:n){
#     filename = paste0("problem_id_",i,".txt")
#     write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
#   }
# }
# pml_write_files(submission)
test$classe <- factor(test$classe)
test$classe <- as.factor(test$classe)
test$classe
predictions <- predict(rf, test)
predictions
setwd("~/R/zrug-rddj")
slidify::publish(user = "grssnbchr", repo "zrug-rddj")
slidify::publish(user = "grssnbchr", repo = "zrug-rddj")
slidify::publish(user = "grssnbchr", repo = "zrug-rddj")
slidify::slidify("index.Rmd")
slidify::publish(user = "grssnbchr", repo = "zrug-rddj")
slidify::slidify("index.Rmd")
slidify::publish(user = "grssnbchr", repo = "zrug-rddj")
slidify::publish(user = "grssnbchr", repo = "zrug-rddj")
slidify::slidify("index.Rmd")
slidify::publish(user = "grssnbchr", repo = "zrug-rddj")
